{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"dockerImageVersionId":30919,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.optim as optim\nimport torchvision\nimport torchvision.transforms as transforms","metadata":{"_uuid":"68bcf541-db2e-40cf-8618-925785d40bf4","_cell_guid":"ec285165-22a6-43c0-9c3c-a6e0220a51e5","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Define transformations (normalize to match pre-trained settings)\ntransform = transforms.Compose([\n    transforms.ToTensor(),\n    transforms.Normalize((0.5,), (0.5,))\n])\n\n# Load CIFAR-10 dataset\ntrainset = torchvision.datasets.CIFAR10(root=\"./data\", train=True, download=True, transform=transform)\ntrain_loader = torch.utils.data.DataLoader(trainset, batch_size=128, shuffle=True)\n\ntestset = torchvision.datasets.CIFAR10(root=\"./data\", train=False, download=True, transform=transform)\ntest_loader = torch.utils.data.DataLoader(testset, batch_size=128, shuffle=False)","metadata":{"_uuid":"7c4e5891-24b8-440a-a4a5-ba6d7abbecee","_cell_guid":"2d82c844-acb2-40cd-94b0-5435a62c125f","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-03-08T09:44:58.775515Z","iopub.execute_input":"2025-03-08T09:44:58.775797Z","iopub.status.idle":"2025-03-08T09:45:03.961974Z","shell.execute_reply.started":"2025-03-08T09:44:58.775773Z","shell.execute_reply":"2025-03-08T09:45:03.961324Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"class ResidualBlock(nn.Module):\n    def __init__(self, in_channels, out_channels, stride=1):\n        super(ResidualBlock, self).__init__()\n        self.conv1 = nn.Conv2d(\n            in_channels,\n            out_channels,\n            kernel_size=3,\n            stride=stride,\n            padding=1,\n            bias=False,\n        )\n        self.bn1 = nn.BatchNorm2d(out_channels)\n        self.conv2 = nn.Conv2d(\n            out_channels, out_channels, kernel_size=3, stride=1, padding=1, bias=False\n        )\n        self.bn2 = nn.BatchNorm2d(out_channels)\n\n        self.shortcut = nn.Sequential()\n        if stride != 1 or in_channels != out_channels:\n            self.shortcut = nn.Sequential(\n                nn.Conv2d(\n                    in_channels, out_channels, kernel_size=1, stride=stride, bias=False\n                ),\n                nn.BatchNorm2d(out_channels),\n            )\n\n    def forward(self, x):\n        out = torch.relu(self.bn1(self.conv1(x)))\n        out = self.bn2(self.conv2(out))\n        out += self.shortcut(x)  \n        return torch.relu(out)\n\n\n\nclass CNN(nn.Module):\n    def __init__(self):\n        super(CNN, self).__init__()\n        self.conv1 = nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1, bias=False)\n        self.bn1 = nn.BatchNorm2d(64)\n\n        self.layer1 = ResidualBlock(64, 128, stride=2)\n        self.layer2 = ResidualBlock(128, 256, stride=2)\n        self.layer3 = ResidualBlock(256, 512, stride=2)\n\n        self.avg_pool = nn.AdaptiveAvgPool2d((1, 1))\n        self.fc = nn.Linear(512, 10)\n\n    def forward(self, x):\n        x = torch.relu(self.bn1(self.conv1(x)))\n        x = self.layer1(x)\n        x = self.layer2(x)\n        x = self.layer3(x)\n        x = self.avg_pool(x)\n        x = torch.flatten(x, 1)\n        return self.fc(x)","metadata":{"_uuid":"023c9a35-5d25-4404-a498-ca27b897ab70","_cell_guid":"c386c74e-a27f-40d9-82d3-9aa886a1baab","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-03-08T09:45:32.801758Z","iopub.execute_input":"2025-03-08T09:45:32.802042Z","iopub.status.idle":"2025-03-08T09:45:32.810872Z","shell.execute_reply.started":"2025-03-08T09:45:32.802020Z","shell.execute_reply":"2025-03-08T09:45:32.809955Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def fgsm_attack(model, images, labels, epsilon=0.1):\n    images = images.clone().detach().to(\"cuda\").requires_grad_(True)\n    labels = labels.to(\"cuda\")\n\n    output = model(images)\n    loss = nn.CrossEntropyLoss()(output, labels)\n\n    model.zero_grad()\n    loss.backward()\n\n    adv_images = images + epsilon * images.grad.sign()\n    adv_images = torch.clamp(adv_images, 0, 1)  # Keep pixel values in valid range\n    return adv_images.detach()","metadata":{"_uuid":"39d95eac-d972-499e-9b33-ebbdb32e7a59","_cell_guid":"c6bd48eb-e454-438b-aa08-acf45f6783ba","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-03-08T09:45:56.194211Z","iopub.execute_input":"2025-03-08T09:45:56.194560Z","iopub.status.idle":"2025-03-08T09:45:56.199628Z","shell.execute_reply.started":"2025-03-08T09:45:56.194529Z","shell.execute_reply":"2025-03-08T09:45:56.198737Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\nmodel = CNN().to(device)\noptimizer = optim.Adam(model.parameters(), lr=0.001)\ncriterion = nn.CrossEntropyLoss()\n\nnum_epochs = 30\nepsilon = 0.1  # FGSM perturbation strength\n\nfor epoch in range(num_epochs):\n    model.train()\n    running_loss = 0.0\n\n    for images, labels in train_loader:\n        images, labels = images.to(device), labels.to(device)\n\n        # Generate adversarial examples\n        adv_images = fgsm_attack(model, images, labels, epsilon=epsilon)\n\n        # Forward pass on clean and adversarial images\n        optimizer.zero_grad()\n        clean_outputs = model(images)\n        adv_outputs = model(adv_images)\n\n        loss_clean = criterion(clean_outputs, labels)\n        loss_adv = criterion(adv_outputs, labels)\n        alpha = max(0.5, 1-epoch/num_epochs)\n        loss = alpha * loss_clean + (1-alpha)*loss_adv\n\n        # Backpropagation\n        loss.backward()\n        optimizer.step()\n\n        running_loss += loss.item()\n\n    print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {running_loss / len(train_loader)}\")\n\n# Save the adversarially trained model\ntorch.save(model.state_dict(), \"/kaggle/working/cifar10_adv_train.pth\")","metadata":{"_uuid":"777b100b-16fa-48c6-8d6f-b478ff884d90","_cell_guid":"8aeca590-0c8e-4c15-a3a5-e9417d466d79","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-03-08T09:47:01.351253Z","iopub.execute_input":"2025-03-08T09:47:01.351629Z","iopub.status.idle":"2025-03-08T09:57:30.386713Z","shell.execute_reply.started":"2025-03-08T09:47:01.351597Z","shell.execute_reply":"2025-03-08T09:57:30.385875Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"_uuid":"ceaecf3c-8e61-48f4-9664-2b037b08e104","_cell_guid":"221fa066-28e4-4975-b4e4-c2e53580619e","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null}]}