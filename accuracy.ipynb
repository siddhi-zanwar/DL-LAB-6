{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":272341,"sourceType":"modelInstanceVersion","isSourceIdPinned":true,"modelInstanceId":233166,"modelId":254890},{"sourceId":279162,"sourceType":"modelInstanceVersion","isSourceIdPinned":true,"modelInstanceId":239139,"modelId":260801},{"sourceId":279813,"sourceType":"modelInstanceVersion","isSourceIdPinned":true,"modelInstanceId":239698,"modelId":261352},{"sourceId":280031,"sourceType":"modelInstanceVersion","isSourceIdPinned":true,"modelInstanceId":239890,"modelId":261545},{"sourceId":280079,"sourceType":"modelInstanceVersion","isSourceIdPinned":true,"modelInstanceId":239934,"modelId":261589}],"dockerImageVersionId":30919,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import torch.nn as nn\nimport torch\nimport torchvision\nimport torchvision.transforms as transforms\nfrom torch.utils.data import DataLoader\nimport matplotlib.pyplot as plt\n\n\nclass ResidualBlock(nn.Module):\n    def __init__(self, in_channels, out_channels, stride=1):\n        super(ResidualBlock, self).__init__()\n        self.conv1 = nn.Conv2d(\n            in_channels,\n            out_channels,\n            kernel_size=3,\n            stride=stride,\n            padding=1,\n            bias=False,\n        )\n        self.bn1 = nn.BatchNorm2d(out_channels)\n        self.conv2 = nn.Conv2d(\n            out_channels, out_channels, kernel_size=3, stride=1, padding=1, bias=False\n        )\n        self.bn2 = nn.BatchNorm2d(out_channels)\n\n        self.shortcut = nn.Sequential()\n        if stride != 1 or in_channels != out_channels:\n            self.shortcut = nn.Sequential(\n                nn.Conv2d(\n                    in_channels, out_channels, kernel_size=1, stride=stride, bias=False\n                ),\n                nn.BatchNorm2d(out_channels),\n            )\n\n    def forward(self, x):\n        out = torch.relu(self.bn1(self.conv1(x)))\n        out = self.bn2(self.conv2(out))\n        out += self.shortcut(x)  \n        return torch.relu(out)\n\n\nclass CNN(nn.Module):\n    def __init__(self):\n        super(CNN, self).__init__()\n        self.conv1 = nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1, bias=False)\n        self.bn1 = nn.BatchNorm2d(64)\n\n        self.layer1 = ResidualBlock(64, 128, stride=2)\n        self.layer2 = ResidualBlock(128, 256, stride=2)\n        self.layer3 = ResidualBlock(256, 512, stride=2)\n\n        self.avg_pool = nn.AdaptiveAvgPool2d((1, 1))\n        self.fc = nn.Linear(512, 10)\n\n    def forward(self, x):\n        x = torch.relu(self.bn1(self.conv1(x)))\n        x = self.layer1(x)\n        x = self.layer2(x)\n        x = self.layer3(x)\n        x = self.avg_pool(x)\n        x = torch.flatten(x, 1)\n        return self.fc(x)","metadata":{"_uuid":"b98a24bc-5fce-40a0-b24c-77f3a12d83d5","_cell_guid":"44147a8a-ae16-45fd-917b-40ed07c1c10f","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"model = CNN()\nmodel.load_state_dict(torch.load(\"/kaggle/input/adtrain/pytorch/default/1/cifar10_adversarial_trained.pth\", weights_only=True))\nmodel.eval()","metadata":{"_uuid":"042332c0-1d8e-436e-b0cb-8782d91b2842","_cell_guid":"59e63713-02a5-45ec-8fa5-8a42c85981f3","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-03-09T07:17:46.409527Z","iopub.execute_input":"2025-03-09T07:17:46.409868Z","iopub.status.idle":"2025-03-09T07:17:47.306463Z","shell.execute_reply.started":"2025-03-09T07:17:46.409838Z","shell.execute_reply":"2025-03-09T07:17:47.305500Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"transform = transforms.Compose([transforms.ToTensor()])\ntest_dataset = torchvision.datasets.CIFAR10(root='./data', train=False, transform=transform, download=True)\ntest_loader = DataLoader(test_dataset, batch_size=1, shuffle=False)","metadata":{"_uuid":"b87fab8a-a7ad-4cfe-8680-5dbeaf835abe","_cell_guid":"1dbe7781-8412-4eeb-bcbd-3b8a00f4dd07","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-03-09T07:17:50.469485Z","iopub.execute_input":"2025-03-09T07:17:50.469796Z","iopub.status.idle":"2025-03-09T07:17:54.673346Z","shell.execute_reply.started":"2025-03-09T07:17:50.469772Z","shell.execute_reply":"2025-03-09T07:17:54.672659Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def evaluate_model(model, image, label):\n    output = model(image)\n    pred = torch.argmax(torch.nn.functional.softmax(output, dim=1))\n    return pred.item(), (pred == label).item()","metadata":{"_uuid":"488a8ce1-406d-4046-b49a-142d71cfef55","_cell_guid":"e812e9e7-3ac1-4ca5-99da-c9ca28cacb8e","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-03-09T07:19:09.538476Z","iopub.execute_input":"2025-03-09T07:19:09.538818Z","iopub.status.idle":"2025-03-09T07:19:09.543083Z","shell.execute_reply.started":"2025-03-09T07:19:09.538789Z","shell.execute_reply":"2025-03-09T07:19:09.542134Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import random","metadata":{"_uuid":"2029fd99-7d8f-4290-bf69-cc8639dcc732","_cell_guid":"d104352e-044c-4bdd-a1f7-6fd550f72464","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"epsilon = 0.1\nnum_samples = 100\ncorrect_clean = 0\ncorrect_adv = 0","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"random_indices = random.sample(range(len(test_dataset)), num_samples)\n\nfor idx in random_indices:\n    image, label = test_dataset[idx]\n    input_image = image.unsqueeze(0)\n    target_class = torch.tensor([label], dtype=torch.long)\n    input_image.requires_grad = True\n\n    # Clean prediction\n    output = model(input_image)\n    loss = nn.CrossEntropyLoss()(output, target_class)\n    \n    # Compute gradients\n    model.zero_grad()\n    loss.backward()\n\n    # Generate adversarial example\n    with torch.no_grad():\n        adversarial_image = input_image + epsilon * input_image.grad.sign()\n        adversarial_image.clamp_(0, 1)\n\n    # Evaluate predictions\n    clean_pred, clean_correct = evaluate_model(model, input_image, label)\n    adv_pred, adv_correct = evaluate_model(model, adversarial_image, label)\n\n    correct_clean += clean_correct\n    correct_adv += adv_correct","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"clean_accuracy = correct_clean / num_samples * 100\nadv_accuracy = correct_adv / num_samples * 100\n\nprint(f\"Accuracy on clean images: {clean_accuracy:.2f}%\")\nprint(f\"Accuracy on adversarial images: {adv_accuracy:.2f}%\")","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}